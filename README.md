### 言語処理について
- **info_density**<br>語句の修飾関係から深さを算出し、より複雑な修飾を受けている語句にハイスコアを割り当てる。スコアはデフォルトで0~1で正規化される。<br><br>*古典的カテゴリー理論やプロトタイプ理論の立場に立つと、語句の持つ概念同士は文脈中で互いに関係性を記述し意味を細分化し合うとも捉えられる。これをもとにすると、より修飾の深い語句は文脈特有の意味を持ち、またその周辺に位置する語句も同様に修飾関係が深い傾向にある。こうしてみると、単に修飾の深さを計測するだけでもその文脈固有の情報が密集している位置を特定できる。*

### 埋め込みベクトルの性質
1. **意味的類似性**<br>コサイン類似度やユークリッド距離の算出によるベクトルの類似性は自然言語的観点における類似性と同等の意味合いを持つ。
2. **意味的線形性**<br>単語・文章の埋め込みベクトルにおいて加減法を適用することは、対応する元の単語・文章における意味の足し引きと同等の意味を持つ。
3. **低次元・密性**<br>従来のOne-hot-Encodingにおける、計算時のメモリ消費及びベクトルの直行による意味表現の限界を解決するために低次元に圧縮。これにより分布仮説が表現される。
4. **文脈依存性**<br>等しい単語・文章についても、与えられる文脈次第で異なるベクトルとなる。